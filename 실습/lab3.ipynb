{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5fc5d3-3e54-4dd9-ae59-4157778b29f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "다음에 제시된 웹 페이지는 다음의 뉴스의 페이지이다. (https://news.daum.net/)\n",
    "이 페이지에서 각 뉴스의 제목과 이 뉴스의 카테고리를 스크래핑(20개)하여 newstitle, newscategory 라는 제목행과 함께 \n",
    "기사 제목과 카테고리명을 컴마(,)로 구분하여 csv 파일(news.csv )로 저장하는 프로그램을 구현하여 메일로 제출한다. \n",
    "pandas 를 학습하기 전이므로 데이터프레임을 생성하여 처리하는 대신 , 로 구분되는 형식으로 만들어서 파일에 출력한다.(수업시간에 다뤘던 소스 참조)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14a940ea-8feb-48d6-9759-ead2fe6ee927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "urlstr = 'https://news.daum.net/'\n",
    "r = requests.get(urlstr)\n",
    "html = r.text\n",
    "\n",
    "bs= BeautifulSoup(html, 'html.parser')\n",
    "categories = []\n",
    "titles = []\n",
    "\n",
    "title = bs.select('.tit_g > a')\n",
    "\n",
    "for tt in title:\n",
    "    titles.append(tt.string)\n",
    "\n",
    "    \n",
    "category = bs.select('.info_thumb > .txt_category')\n",
    "for ct in category:\n",
    "    categories.append(ct.string)\n",
    "\n",
    "   \n",
    "with open('output/news.csv','wt',encoding='utf-8') as f:\n",
    "    f.write('category,titles\\n')\n",
    "    for i in range(len(categories)):\n",
    "        f.write(categories[i]+\",\"+titles[i].strip()+'\\n')  \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
